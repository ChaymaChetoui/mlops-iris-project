# ğŸŒ¸ MLOps Iris Classification

Projet MLOps complet implÃ©mentant un workflow de bout en bout pour la classification multi-classe sur le dataset Iris, avec versioning, expÃ©rimentation, orchestration et dÃ©ploiement automatisÃ©.

[![CI/CD](https://github.com/ChaymaChetoui/mlops-iris-project/actions/workflows/ci.yml/badge.svg)](https://github.com/ChaymaChetoui/mlops-iris-project/actions)

## ğŸ¯ Objectifs du projet

Ce projet dÃ©montre l'implÃ©mentation d'une stack MLOps moderne comprenant :

- **Versioning** : Git (branches `dev`/`main`, tags v1/v2) + DVC (donnÃ©es et modÃ¨les)
- **ExpÃ©rimentation** : MLflow (tracking) + Optuna (optimisation d'hyperparamÃ¨tres)
- **Orchestration** : ZenML (pipeline reproductible)
- **DÃ©ploiement** : FastAPI + Docker + Docker Compose
- **CI/CD** : GitHub Actions (tests, build, dÃ©ploiement)

## ğŸ“ Structure du projet

```
mlops-iris-project/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml              # CI/CD Pipeline
â”œâ”€â”€ .dvc/                       # Configuration DVC
â”œâ”€â”€ artifacts/                  # ModÃ¨les sauvegardÃ©s
â”‚   â”œâ”€â”€ model_v1.pkl           # Baseline LogisticRegression
â”‚   â”œâ”€â”€ model_v2.pkl           # Meilleur modÃ¨le (SVM, acc: 1.0)
â”‚   â””â”€â”€ optuna_best_model_final.pkl
â”œâ”€â”€ data/
â”‚   â””â”€â”€ iris.csv               # Dataset (versionnÃ© avec DVC)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py                 # API FastAPI
â”‚   â”œâ”€â”€ optuna_study.py        # Optimisation hyperparamÃ¨tres
â”‚   â”œâ”€â”€ pipeline.py            # Pipeline ZenML
â”‚   â”œâ”€â”€ prepare_data.py        # PrÃ©paration des donnÃ©es
â”‚   â””â”€â”€ train.py               # EntraÃ®nement des modÃ¨les
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_model.py          # Tests unitaires
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Installation et dÃ©marrage

### PrÃ©requis

- Python 3.10
- Docker & Docker Compose
- Git & DVC

### 1. Cloner le projet

```bash
git clone https://github.com/ChaymaChetoui/mlops-iris-project.git
cd mlops-iris-project
```

### 2. RÃ©cupÃ©rer les donnÃ©es

```bash
dvc pull  # TÃ©lÃ©charge iris.csv depuis le remote DVC
```

### 3. Configurer l'environnement

```bash
# CrÃ©er l'environnement virtuel
python -m venv venv

# Activer l'environnement
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸ”¬ ExpÃ©rimentation et entraÃ®nement

### Suivi avec MLflow

Lancez l'interface MLflow pour visualiser toutes les expÃ©riences :

```bash
mlflow ui
```

AccÃ©dez Ã  http://localhost:5000 pour voir :

- âœ… Run baseline (LogisticRegression)
- âœ… Variations manuelles (diffÃ©rents hyperparamÃ¨tres)
- âœ… Ã‰tude Optuna (10 trials avec child runs)
- âœ… Meilleur modÃ¨le (SVM, accuracy: 1.0)

![MLflow UI](docs/screenshots/mlFlowcapture.png)
![MLflow UI](docs/screenshots/mlFlowcapture2.png)
![MLflow UI](docs/screenshots/mlflowcaptur3.png)
*Interface MLflow montrant l'historique des expÃ©riences et les mÃ©triques*

### Pipeline ZenML

ExÃ©cutez le pipeline complet de ML :

```bash
python src/pipeline.py
zenml up --blocking
```

AccÃ©dez Ã  http://localhost:8237 pour visualiser :

**DAG du pipeline** : `load_data` â†’ `split_data` â†’ `train_model` â†’ `evaluate_model`

![ZenML Pipeline](docs/screenshots/zenml.png)
![ZenML Pipeline](docs/screenshots/zen.png)
![ZenML Pipeline](docs/screenshots/capturezen.png)
*Pipeline ZenML avec les diffÃ©rentes Ã©tapes et artefacts*

Les artefacts sont automatiquement sauvegardÃ©s dans `artifacts/`.

### Optimisation avec Optuna

Lancez une Ã©tude d'optimisation des hyperparamÃ¨tres :

```bash
python src/optuna_study.py
```

Cette Ã©tude :
- Teste 10 combinaisons d'hyperparamÃ¨tres
- Logs tous les trials dans MLflow (parent + child runs)
- Sauvegarde automatiquement le meilleur modÃ¨le

![Optuna Study](docs/screenshots/optuna.png)
*RÃ©sultats de l'optimisation Optuna avec les meilleurs hyperparamÃ¨tres*

## ğŸŒ DÃ©ploiement de l'API

### Lancer l'API avec Docker Compose

```bash
docker-compose up --build
```

L'API est accessible sur http://localhost:8000

![API FastAPI](docs/screenshots/resultat.png)
![API FastAPI](docs/screenshots/res2.png)



### Tester les prÃ©dictions

**Page d'accueil** :
```bash
curl http://localhost:8000/
```

**PrÃ©dire une espÃ¨ce Iris** :

```bash
# Setosa
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [5.1, 3.5, 1.4, 0.2]}'

# Versicolor
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [6.3, 3.3, 4.7, 1.6]}'

# Virginica
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [6.7, 3.0, 5.2, 2.3]}'
```

### Gestion des versions de modÃ¨le

Pour changer de version, modifiez `MODEL_VERSION` dans `docker-compose.yml` :

- `v1` : ModÃ¨le baseline (LogisticRegression)
- `v2` : Meilleur modÃ¨le Optuna (SVM, accuracy: 1.0)

```yaml
environment:
  - MODEL_VERSION=v2  # Changer ici
```

Puis relancez :

```bash
docker-compose up --build
```

**StratÃ©gie de dÃ©ploiement testÃ©e** :
1. âœ… DÃ©ploiement initial avec v1
2. âœ… Migration vers v2 (meilleur modÃ¨le)
3. âœ… Rollback vers v1 (si nÃ©cessaire)
## ğŸŒ DÃ©ploiement live avec interface web interactive

Le projet est dÃ©ployÃ© en live sur AWS EC2 avec une interface Gradio interactive permettant de tester les prÃ©dictions en temps rÃ©el.

### URL fixe pour tester l'interface (Elastic IP)
**Interface Gradio live :**  
http://34.193.10.232:7860/

**Instructions pour tester :**
1. Ouvrez le lien ci-dessus dans votre navigateur
2. DÃ©placez les curseurs pour entrer les mesures de la fleur Iris
3. Cliquez sur **Submit**
4. Vous verrez la prÃ©diction instantanÃ©e (setosa, versicolor ou virginica) ğŸŒ¸

**Exemples rapides Ã  tester :**
- Setosa : [5.1, 3.5, 1.4, 0.2]
- Versicolor : [6.4, 3.2, 4.5, 1.5]
- Virginica : [7.7, 3.8, 6.7, 2.2]

**Note :**  
L'URL est fixe grÃ¢ce Ã  une Elastic IP AWS. L'instance doit Ãªtre en cours d'exÃ©cution et `python app.py` lancÃ© sur le serveur pour que l'interface soit accessible.


## ğŸ”„ CI/CD avec GitHub Actions

Le workflow `.github/workflows/ci.yml` s'exÃ©cute automatiquement Ã  chaque push sur `dev` ou `main` :

### Pipeline CI/CD

1. **Linting** : VÃ©rification du code avec `flake8`
2. **Tests unitaires** : ExÃ©cution de `pytest`
3. **Build Docker** : Construction de l'image
4. **Push Registry** : Publication sur GitHub Container Registry (`ghcr.io`)
5. **Smoke test** : Validation quotidienne automatique

![GitHub Actions](docs/screenshots/cicd.png)
*Workflow CI/CD avec tous les jobs rÃ©ussis*

Consultez l'onglet [Actions](https://github.com/ChaymaChetoui/mlops-iris-project/actions) pour voir l'historique des builds.

## ğŸ“Š RÃ©sultats

| ModÃ¨le | Accuracy | HyperparamÃ¨tres | Version |
|--------|----------|-----------------|---------|
| LogisticRegression (baseline) | 0.97 | C=1.0 | v1 |
| **SVM (Optuna)** | **1.00** | **C=10, kernel=rbf** | **v2** |

## ğŸ§ª Tests

Lancer les tests unitaires :

```bash
pytest tests/
```

## ğŸ“ Commandes utiles

```bash
# DVC
dvc add data/iris.csv          # Versionner un fichier
dvc push                       # Pousser vers le remote
dvc pull                       # RÃ©cupÃ©rer depuis le remote

# Git
git checkout dev               # Basculer sur dev
git tag v1                     # CrÃ©er un tag

# Docker
docker-compose logs -f         # Voir les logs en temps rÃ©el
docker-compose down            # ArrÃªter les conteneurs

# ZenML
zenml stack list               # Lister les stacks
zenml pipeline runs list       # Historique des runs
```

## ğŸ› ï¸ Technologies utilisÃ©es

- **ML/Data** : scikit-learn, pandas, numpy
- **MLOps** : MLflow, ZenML, DVC, Optuna
- **API** : FastAPI, uvicorn
- **Containerisation** : Docker, Docker Compose
- **CI/CD** : GitHub Actions
- **Versioning** : Git, DVC

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“„ Licence

Ce projet est sous licence MIT.

## ğŸ‘¤ Auteur

**Chayma Chetoui**

- GitHub: [@ChaymaChetoui](https://github.com/ChaymaChetoui)

---

â­ Si ce projet vous a aidÃ©, n'hÃ©sitez pas Ã  lui donner une Ã©toile !
